{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_Train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "19oA4_oTsE0hVBM980UkwDYGe-MVHwioR",
      "authorship_tag": "ABX9TyMFtZ7fVokjKtchF5bbJFWJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheBProgrammer/BERT-test/blob/main/BERT_Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-pretrained-bert==0.4.0\n",
        "#/content/drive\n",
        "#ids.append(self.vocab.get(token, self.vocab['[UNK]']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nnv8MzM7psP3",
        "outputId": "43c4b422-3bdf-4fd0-a496-9699399c8152"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-pretrained-bert==0.4.0 in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.4.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.4.0) (1.19.5)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.4.0) (1.20.26)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.4.0) (4.62.3)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.4.0) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert==0.4.0) (3.10.0.2)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert==0.4.0) (0.5.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert==0.4.0) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.24.0,>=1.23.26 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert==0.4.0) (1.23.26)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.26->boto3->pytorch-pretrained-bert==0.4.0) (1.25.11)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.26->boto3->pytorch-pretrained-bert==0.4.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.26->boto3->pytorch-pretrained-bert==0.4.0) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert==0.4.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert==0.4.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert==0.4.0) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/BERT-keyphrase-extraction-master')"
      ],
      "metadata": {
        "id": "YyRZmgGcp5ow"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sxrB7nqlTpdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eecb5214-c83d-4a53-c17f-9367e94acf2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import random\n",
        "import logging\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "import torch.nn as nn\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from tqdm import trange\n",
        "\n",
        "from pytorch_pretrained_bert import BertForTokenClassification\n",
        "\n",
        "from data_loader import DataLoader\n",
        "from evaluate import evaluate\n",
        "import utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--data_dir', default='/content/drive/MyDrive/BERT-keyphrase-extraction-master/data/task1', help=\"Directory containing the dataset\")\n",
        "parser.add_argument('--bert_model_dir', default='/content/drive/MyDrive/BERT-keyphrase-extraction-master/model', help=\"Directory containing the BERT model in PyTorch\")\n",
        "parser.add_argument('--model_dir', default='/content/drive/MyDrive/BERT-keyphrase-extraction-master/experiments/base_model', help=\"Directory containing params.json\")\n",
        "parser.add_argument('--seed', type=int, default=2019, help=\"random seed for initialization\")\n",
        "parser.add_argument('--restore_file', default='/content/drive/MyDrive/BERT-keyphrase-extraction-master/experiments/base_model/best.pth.tar',\n",
        "                    help=\"Optional, name of the file in --model_dir containing weights to reload before training\")\n",
        "parser.add_argument('--multi_gpu', default=False, action='store_true', help=\"Whether to use multiple GPUs if available\")\n",
        "parser.add_argument('--fp16', default=False, action='store_true', help=\"Whether to use 16-bit float precision instead of 32-bit\")\n",
        "parser.add_argument('--loss_scale', type=float, default=0,\n",
        "                        help=\"Loss scaling to improve fp16 numeric stability. Only used when fp16 set to True.\\n\"\n",
        "                             \"0 (default value): dynamic loss scaling.\\n\"\n",
        "                             \"Positive power of 2: static loss scaling value.\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K184UUSNlCMW",
        "outputId": "4832e9b8-de02-43c2-fa3d-fdb19e5c02e4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--loss_scale'], dest='loss_scale', nargs=None, const=None, default=0, type=<class 'float'>, choices=None, help='Loss scaling to improve fp16 numeric stability. Only used when fp16 set to True.\\n0 (default value): dynamic loss scaling.\\nPositive power of 2: static loss scaling value.\\n', metavar=None)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data_iterator, optimizer, scheduler, params):\n",
        "    \"\"\"Train the model on `steps` batches\"\"\"\n",
        "    # set model to training mode\n",
        "    model.train()\n",
        "    scheduler.step()\n",
        "\n",
        "    # a running average object for loss\n",
        "    loss_avg = utils.RunningAverage()\n",
        "    \n",
        "    # Use tqdm for progress bar\n",
        "    t = trange(params.train_steps)\n",
        "    for i in t:\n",
        "        # fetch the next training batch\n",
        "        batch_data, batch_tags = next(data_iterator)\n",
        "        batch_masks = batch_data.gt(0)\n",
        "\n",
        "        # compute model output and loss\n",
        "        loss = model(batch_data, token_type_ids=None, attention_mask=batch_masks, labels=batch_tags)\n",
        "\n",
        "        if params.n_gpu > 1 and args.multi_gpu:\n",
        "            loss = loss.mean()  # mean() to average on multi-gpu\n",
        "\n",
        "        # clear previous gradients, compute gradients of all variables wrt loss\n",
        "        model.zero_grad()\n",
        "        if args.fp16:\n",
        "            optimizer.backward(loss)\n",
        "        else:\n",
        "            loss.backward()\n",
        "\n",
        "        # gradient clipping\n",
        "        nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=params.clip_grad)\n",
        "\n",
        "        # performs updates using calculated gradients\n",
        "        optimizer.step()\n",
        "\n",
        "        # update the average loss\n",
        "        loss_avg.update(loss.item())\n",
        "        t.set_postfix(loss='{:05.3f}'.format(loss_avg()))"
      ],
      "metadata": {
        "id": "LPNenulLlCRL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model, train_data, val_data, optimizer, scheduler, params, model_dir, restore_file=None):\n",
        "    \"\"\"Train the model and evaluate every epoch.\"\"\"\n",
        "    # reload weights from restore_file if specified\n",
        "    if restore_file is not None:\n",
        "        restore_path = os.path.join(args.model_dir, args.restore_file + '.pth.tar')\n",
        "        logging.info(\"Restoring parameters from {}\".format(restore_path))\n",
        "        utils.load_checkpoint(restore_path, model, optimizer)\n",
        "        \n",
        "    best_val_f1 = 0.0\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(1, params.epoch_num + 1):\n",
        "        # Run one epoch\n",
        "        logging.info(\"Epoch {}/{}\".format(epoch, params.epoch_num))\n",
        "\n",
        "        # Compute number of batches in one epoch\n",
        "        params.train_steps = params.train_size // params.batch_size\n",
        "        params.val_steps = params.val_size // params.batch_size\n",
        "\n",
        "        # data iterator for training\n",
        "        train_data_iterator = data_loader.data_iterator(train_data, shuffle=True)\n",
        "        # Train for one epoch on training set\n",
        "        train(model, train_data_iterator, optimizer, scheduler, params)\n",
        "\n",
        "        # data iterator for evaluation\n",
        "        train_data_iterator = data_loader.data_iterator(train_data, shuffle=False)\n",
        "        val_data_iterator = data_loader.data_iterator(val_data, shuffle=False)\n",
        "\n",
        "        # Evaluate for one epoch on training set and validation set\n",
        "        params.eval_steps = params.train_steps\n",
        "        train_metrics = evaluate(model, train_data_iterator, params, mark='Train', verbose=True)\n",
        "        params.eval_steps = params.val_steps\n",
        "        val_metrics = evaluate(model, val_data_iterator, params, mark='Val', verbose=True)\n",
        "        \n",
        "        val_f1 = val_metrics['f1']\n",
        "        improve_f1 = val_f1 - best_val_f1\n",
        "\n",
        "        # Save weights of the network\n",
        "        model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
        "        optimizer_to_save = optimizer.optimizer if args.fp16 else optimizer\n",
        "        utils.save_checkpoint({'epoch': epoch + 1,\n",
        "                               'state_dict': model_to_save.state_dict(),\n",
        "                               'optim_dict': optimizer_to_save.state_dict()},\n",
        "                               is_best=improve_f1>0,\n",
        "                               checkpoint=model_dir)\n",
        "        if improve_f1 > 0:\n",
        "            logging.info(\"- Found new best F1\")\n",
        "            best_val_f1 = val_f1\n",
        "            if improve_f1 < params.patience:\n",
        "                patience_counter += 1\n",
        "            else:\n",
        "                patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping and logging best f1\n",
        "        if (patience_counter >= params.patience_num and epoch > params.min_epoch_num) or epoch == params.epoch_num:\n",
        "            logging.info(\"Best val f1: {:05.2f}\".format(best_val_f1))\n",
        "            break "
      ],
      "metadata": {
        "id": "G6bYggfqlCcS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.argv=['']\n",
        "del sys"
      ],
      "metadata": {
        "id": "Hd93EW_Btg1N"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Load the parameters from json file\n",
        "    json_path = os.path.join(args.model_dir, 'params.json')\n",
        "    assert os.path.isfile(json_path), \"No json configuration file found at {}\".format(json_path)\n",
        "    params = utils.Params(json_path)\n",
        "\n",
        "    # Use GPUs if available\n",
        "    params.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    params.n_gpu = torch.cuda.device_count()\n",
        "    params.multi_gpu = args.multi_gpu\n",
        "\n",
        "    # Set the random seed for reproducible experiments\n",
        "    random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    if params.n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(args.seed)  # set random seed for all GPUs\n",
        "    params.seed = args.seed\n",
        "    \n",
        "    # Set the logger\n",
        "    utils.set_logger(os.path.join(args.model_dir, 'train.log'))\n",
        "    logging.info(\"device: {}, n_gpu: {}, 16-bits training: {}\".format(params.device, params.n_gpu, args.fp16))\n",
        "\n",
        "    # Create the input data pipeline\n",
        "    logging.info(\"Loading the datasets...\")\n",
        "    \n",
        "    # Initialize the DataLoader\n",
        "    data_loader = DataLoader(args.data_dir, args.bert_model_dir, params, token_pad_idx=0)\n",
        "    \n",
        "    # Load training data and test data\n",
        "    train_data = data_loader.load_data('train')\n",
        "    val_data = data_loader.load_data('val')\n",
        "\n",
        "    # Specify the training and validation dataset sizes\n",
        "    params.train_size = train_data['size']\n",
        "    params.val_size = val_data['size']\n",
        "\n",
        "    # Prepare model\n",
        "    model = BertForTokenClassification.from_pretrained(args.bert_model_dir, num_labels=len(params.tag2idx))\n",
        "    model.to(params.device)\n",
        "    if args.fp16:\n",
        "        model.half()\n",
        "\n",
        "    if params.n_gpu > 1 and args.multi_gpu:\n",
        "        model = torch.nn.DataParallel(model)\n",
        "\n",
        "    # Prepare optimizer\n",
        "    if params.full_finetuning:\n",
        "        param_optimizer = list(model.named_parameters())\n",
        "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "        # no_decay = ['bias', 'gamma', 'beta']\n",
        "        optimizer_grouped_parameters = [\n",
        "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n",
        "             'weight_decay_rate': 0.01},\n",
        "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n",
        "             'weight_decay_rate': 0.0}\n",
        "        ]\n",
        "    else:\n",
        "        param_optimizer = list(model.classifier.named_parameters()) \n",
        "        optimizer_grouped_parameters = [{'params': [p for n, p in param_optimizer]}]\n",
        "    if args.fp16:\n",
        "        try:\n",
        "            from apex.optimizers import FP16_Optimizer\n",
        "            from apex.optimizers import FusedAdam\n",
        "        except ImportError:\n",
        "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
        "        optimizer = FusedAdam(optimizer_grouped_parameters,\n",
        "                              lr=params.learning_rate,\n",
        "                              bias_correction=False,\n",
        "                              max_grad_norm=1.0)\n",
        "        scheduler = LambdaLR(optimizer, lr_lambda=lambda epoch: 1/(1 + 0.05*epoch))\n",
        "        if args.loss_scale == 0:\n",
        "            optimizer = FP16_Optimizer(optimizer, dynamic_loss_scale=True)\n",
        "        else:\n",
        "            optimizer = FP16_Optimizer(optimizer, static_loss_scale=args.loss_scale)\n",
        "    else:\n",
        "        optimizer = Adam(optimizer_grouped_parameters, lr=params.learning_rate)\n",
        "        scheduler = LambdaLR(optimizer, lr_lambda=lambda epoch: 1/(1 + 0.05*epoch))\n",
        "\n",
        "    # Train and evaluate the model\n",
        "    logging.info(\"Starting training for {} epoch(s)\".format(params.epoch_num))\n",
        "    train_and_evaluate(model, train_data, val_data, optimizer, scheduler, params, args.model_dir, args.restore_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G10bwbmNlCkR",
        "outputId": "9d9885c1-6ad4-4958-d48f-3dc30b046e2b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "device: cuda, n_gpu: 1, 16-bits training: False\n",
            "Loading the datasets...\n",
            "loading vocabulary file /content/drive/MyDrive/BERT-keyphrase-extraction-master/model/vocab.txt\n",
            "loading archive file /content/drive/MyDrive/BERT-keyphrase-extraction-master/model\n",
            "Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "Weights of BertForTokenClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
            "Weights from pretrained model not used in BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "Starting training for 20 epoch(s)\n",
            "Epoch 1/20\n",
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "100%|██████████| 99/99 [00:35<00:00,  2.76it/s, loss=0.310]\n",
            "- Train metrics: loss: 00.19; f1: 39.71\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          I      36.21     43.95     39.71      3024\n",
            "\n",
            "avg / total      36.21     43.95     39.71      3024\n",
            "\n",
            "- Val metrics: loss: 00.24; f1: 32.27\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          I      29.13     36.16     32.27       921\n",
            "\n",
            "avg / total      29.13     36.16     32.27       921\n",
            "\n",
            "- Found new best F1\n",
            "Epoch 2/20\n",
            "100%|██████████| 99/99 [00:36<00:00,  2.74it/s, loss=0.181]\n",
            "- Train metrics: loss: 00.11; f1: 59.85\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          I      58.01     61.81     59.85      3024\n",
            "\n",
            "avg / total      58.01     61.81     59.85      3024\n",
            "\n",
            "- Val metrics: loss: 00.23; f1: 41.29\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          I      39.00     43.87     41.29       921\n",
            "\n",
            "avg / total      39.00     43.87     41.29       921\n",
            "\n",
            "- Found new best F1\n",
            "Epoch 3/20\n",
            "100%|██████████| 99/99 [00:36<00:00,  2.75it/s, loss=0.127]\n",
            "- Train metrics: loss: 00.08; f1: 70.42\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          I      69.62     71.23     70.42      3024\n",
            "\n",
            "avg / total      69.62     71.23     70.42      3024\n",
            "\n",
            "- Val metrics: loss: 00.28; f1: 43.13\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          I      41.55     44.84     43.13       921\n",
            "\n",
            "avg / total      41.55     44.84     43.13       921\n",
            "\n",
            "- Found new best F1\n",
            "Epoch 4/20\n",
            "100%|██████████| 99/99 [00:36<00:00,  2.71it/s, loss=0.087]\n",
            "- Train metrics: loss: 00.06; f1: 76.21\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          I      75.48     76.95     76.21      3024\n",
            "\n",
            "avg / total      75.48     76.95     76.21      3024\n",
            "\n",
            "- Val metrics: loss: 00.33; f1: 43.95\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          I      41.95     46.15     43.95       921\n",
            "\n",
            "avg / total      41.95     46.15     43.95       921\n",
            "\n",
            "- Found new best F1\n",
            "Epoch 5/20\n",
            "100%|██████████| 99/99 [00:35<00:00,  2.75it/s, loss=0.064]\n",
            "- Train metrics: loss: 00.03; f1: 85.19\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          I      83.42     87.04     85.19      3024\n",
            "\n",
            "avg / total      83.42     87.04     85.19      3024\n",
            "\n",
            "- Val metrics: loss: 00.26; f1: 46.44\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          I      42.84     50.71     46.44       921\n",
            "\n",
            "avg / total      42.84     50.71     46.44       921\n",
            "\n",
            "- Found new best F1\n",
            "Epoch 6/20\n",
            "100%|██████████| 99/99 [00:36<00:00,  2.72it/s, loss=0.044]\n",
            "- Train metrics: loss: 00.02; f1: 91.74\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          I      91.07     92.43     91.74      3024\n",
            "\n",
            "avg / total      91.07     92.43     91.74      3024\n",
            "\n",
            "- Val metrics: loss: 00.29; f1: 49.67\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          I      46.83     52.88     49.67       921\n",
            "\n",
            "avg / total      46.83     52.88     49.67       921\n",
            "\n",
            "- Found new best F1\n",
            "Epoch 7/20\n",
            "100%|██████████| 99/99 [00:35<00:00,  2.75it/s, loss=0.036]\n",
            "- Train metrics: loss: 00.02; f1: 91.22\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          I      90.69     91.77     91.22      3024\n",
            "\n",
            "avg / total      90.69     91.77     91.22      3024\n",
            "\n",
            "- Val metrics: loss: 00.43; f1: 46.31\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          I      44.46     48.32     46.31       921\n",
            "\n",
            "avg / total      44.46     48.32     46.31       921\n",
            "\n",
            "Epoch 8/20\n",
            "100%|██████████| 99/99 [00:36<00:00,  2.72it/s, loss=0.024]\n",
            "- Train metrics: loss: 00.01; f1: 95.77\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          I      95.68     95.87     95.77      3024\n",
            "\n",
            "avg / total      95.68     95.87     95.77      3024\n",
            "\n",
            "- Val metrics: loss: 00.36; f1: 48.38\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          I      46.71     50.16     48.38       921\n",
            "\n",
            "avg / total      46.71     50.16     48.38       921\n",
            "\n",
            "Epoch 9/20\n",
            "100%|██████████| 99/99 [00:36<00:00,  2.74it/s, loss=0.016]\n",
            "- Train metrics: loss: 00.01; f1: 96.60\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          I      96.47     96.73     96.60      3024\n",
            "\n",
            "avg / total      96.47     96.73     96.60      3024\n",
            "\n",
            "- Val metrics: loss: 00.38; f1: 47.93\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          I      45.35     50.81     47.93       921\n",
            "\n",
            "avg / total      45.35     50.81     47.93       921\n",
            "\n",
            "Best val f1: 49.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from metrics import f1_score\n",
        "from metrics import classification_report"
      ],
      "metadata": {
        "id": "igfSDmq6_-Lk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data_iterator, params, mark='Eval', verbose=False):\n",
        "    \"\"\"Evaluate the model on `steps` batches.\"\"\"\n",
        "    # set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    idx2tag = params.idx2tag\n",
        "\n",
        "    true_tags = []\n",
        "    pred_tags = []\n",
        "\n",
        "    # a running average object for loss\n",
        "    loss_avg = utils.RunningAverage()\n",
        "\n",
        "    for _ in range(params.eval_steps):\n",
        "        # fetch the next evaluation batch\n",
        "        batch_data, batch_tags = next(data_iterator)\n",
        "        batch_masks = batch_data.gt(0)\n",
        "\n",
        "        loss = model(batch_data, token_type_ids=None, attention_mask=batch_masks, labels=batch_tags)\n",
        "        if params.n_gpu > 1 and params.multi_gpu:\n",
        "            loss = loss.mean()\n",
        "        loss_avg.update(loss.item())\n",
        "        \n",
        "        batch_output = model(batch_data, token_type_ids=None, attention_mask=batch_masks)  # shape: (batch_size, max_len, num_labels)\n",
        "        \n",
        "        batch_output = batch_output.detach().cpu().numpy()\n",
        "        batch_tags = batch_tags.to('cpu').numpy()\n",
        "\n",
        "        pred_tags.extend([idx2tag.get(idx) for indices in np.argmax(batch_output, axis=2) for idx in indices])\n",
        "        true_tags.extend([idx2tag.get(idx) for indices in batch_tags for idx in indices])\n",
        "    assert len(pred_tags) == len(true_tags)\n",
        "\n",
        "    # logging loss, f1 and report\n",
        "    metrics = {}\n",
        "    f1 = f1_score(true_tags, pred_tags)\n",
        "    metrics['loss'] = loss_avg()\n",
        "    metrics['f1'] = f1\n",
        "    metrics_str = \"; \".join(\"{}: {:05.2f}\".format(k, v) for k, v in metrics.items())\n",
        "    logging.info(\"- {} metrics: \".format(mark) + metrics_str)\n",
        "\n",
        "    if verbose:\n",
        "        report = classification_report(true_tags, pred_tags)\n",
        "        logging.info(report)\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "zUtfQCDn_03Q"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_pretrained_bert import BertForTokenClassification, BertConfig\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "8kz-nOTXATMa"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Load the parameters from json file\n",
        "    json_path = os.path.join(args.model_dir, 'params.json')\n",
        "    assert os.path.isfile(json_path), \"No json configuration file found at {}\".format(json_path)\n",
        "    params = utils.Params(json_path)\n",
        "\n",
        "    # Use GPUs if available\n",
        "    params.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    params.n_gpu = torch.cuda.device_count()\n",
        "    params.multi_gpu = args.multi_gpu\n",
        "\n",
        "    # Set the random seed for reproducible experiments\n",
        "    random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    if params.n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(args.seed)  # set random seed for all GPUs\n",
        "    params.seed = args.seed\n",
        "\n",
        "    # Set the logger\n",
        "    utils.set_logger(os.path.join(args.model_dir, 'evaluate.log'))\n",
        "\n",
        "    # Create the input data pipeline\n",
        "    logging.info(\"Loading the dataset...\")\n",
        "\n",
        "    # Initialize the DataLoader\n",
        "    data_loader = DataLoader(args.data_dir, args.bert_model_dir, params, token_pad_idx=0)\n",
        "\n",
        "    # Load data\n",
        "    test_data = data_loader.load_data('test')\n",
        "\n",
        "    # Specify the test set size\n",
        "    params.test_size = test_data['size']\n",
        "    params.eval_steps = params.test_size // params.batch_size\n",
        "    test_data_iterator = data_loader.data_iterator(test_data, shuffle=False)\n",
        "\n",
        "    logging.info(\"- done.\")\n",
        "\n",
        "    # Define the model\n",
        "    config_path = os.path.join(args.bert_model_dir, 'bert_config.json')\n",
        "    config = BertConfig.from_json_file(config_path)\n",
        "    model = BertForTokenClassification(config, num_labels=len(params.tag2idx))\n",
        "\n",
        "    model.to(params.device)\n",
        "    # Reload weights from the saved file\n",
        "    utils.load_checkpoint('/content/drive/MyDrive/BERT-keyphrase-extraction-master/experiments/base_model/best.pth.tar', model)\n",
        "    if args.fp16:\n",
        "        model.half()\n",
        "    if params.n_gpu > 1 and args.multi_gpu:\n",
        "        model = torch.nn.DataParallel(model)\n",
        "\n",
        "    logging.info(\"Starting evaluation...\")\n",
        "    test_metrics = evaluate(model, test_data_iterator, params, mark='Test', verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBVpDfBvAA_T",
        "outputId": "33ef29e4-448a-4ea0-bc5e-500ad991d705"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading the dataset...\n",
            "loading vocabulary file /content/drive/MyDrive/BERT-keyphrase-extraction-master/model/vocab.txt\n",
            "- done.\n",
            "Starting evaluation...\n",
            "- Test metrics: loss: 00.29; f1: 49.67\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          I      46.83     52.88     49.67       921\n",
            "\n",
            "avg / total      46.83     52.88     49.67       921\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Keyword extraction of the given file using yake library\n",
        "'''\n",
        "\n",
        "import yake\n",
        "with open('/content/drive/MyDrive/BERT-keyphrase-extraction-master/h1_7.txt') as f:\n",
        "    text = f.read()\n",
        "language = \"en\"\n",
        "max_ngram_size = 3\n",
        "deduplication_threshold = 0.9\n",
        "numOfKeywords = 20\n",
        "extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold, top=numOfKeywords, features=None)"
      ],
      "metadata": {
        "id": "RZ4GefA-EwbV"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keywords = extractor.extract_keywords(text)\n",
        "for kw in keywords:\n",
        "  print(kw[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSRAXk4vEt-Z",
        "outputId": "c11e7858-f784-4b96-b459-3f126ba0a0e9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query\n",
            "Search\n",
            "search request\n",
            "field\n",
            "fields\n",
            "request\n",
            "default\n",
            "search API\n",
            "Defaults\n",
            "document\n",
            "API\n",
            "documents\n",
            "set\n",
            "number\n",
            "Multi Search API\n",
            "Search Shards API\n",
            "search results\n",
            "query string\n",
            "search query\n",
            "search template request\n"
          ]
        }
      ]
    }
  ]
}